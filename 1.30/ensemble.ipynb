{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "\n",
    "The following notebook is a combination of guided exploration of the random forest model using our hr dataset.\n",
    "\n",
    "Your job is to fill in the missing code-blocks and analyze the outputs that your code produces.\n",
    "\n",
    "Credit to [fares-ds](https://github.com/fares-ds) for the notebook.\n",
    "\n",
    "Modifications to instructions and code are indicated via a note from me: (*Note*: ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Decision Trees are an important type of algorithm for predictive modeling machine learning.\n",
    "\n",
    "The classical decision tree algorithms have been around for decades and modern variations like random forest are among the most powerful techniques available.\n",
    "\n",
    "Classification and Regression Trees or CART for short is a term introduced by Leo Breiman to refer to Decision Tree algorithms that can be used for classification or regression predictive modeling problems.\n",
    "\n",
    "Classically, this algorithm is referred to as “decision trees”, but on some platforms like R they are referred to by the more modern term CART.\n",
    "\n",
    "The CART algorithm provides a foundation for important algorithms like bagged decision trees, random forest and boosted decision trees.\n",
    "\n",
    "**CART Model Representation**\n",
    "\n",
    "The representation for the CART model is a binary tree.\n",
    "\n",
    "This is your binary tree from algorithms and data structures, nothing too fancy. Each root node represents a single input variable (x) and a split point on that variable (assuming the variable is numeric).\n",
    "\n",
    "The leaf nodes of the tree contain an output variable (y) which is used to make a prediction.\n",
    "\n",
    "Given a new input, the tree is traversed by evaluating the specific input started at the root node of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros \n",
    "\n",
    "* Simple to understand and to interpret. Trees can be visualised.  \n",
    "* Requires little data preparation.  \n",
    "* Able to handle both numerical and categorical data. \n",
    "* Possible to validate a model using statistical tests.  \n",
    "* Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cons\n",
    "\n",
    "* Overfitting. Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node or setting the maximum depth of the tree are necessary to avoid this problem.  \n",
    "* Decision trees can be unstable. Mitigant: Use decision trees within an ensemble.  \n",
    "* Cannot guarantee to return the globally optimal decision tree. Mitigant: Training multiple trees in an ensemble learner  \n",
    "* Decision tree learners create biased trees if some classes dominate. Recommendation: Balance the dataset prior to fitting  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random Forest is one of the most popular and most powerful machine learning algorithms. It is a type of ensemble machine learning algorithm called Bootstrap Aggregation or bagging.\n",
    "\n",
    "To improve performance of Decision trees, we can use many trees with a random sample of features chosen as the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree & Random Forest Implementation in python\n",
    "\n",
    "We will use Decision Tree & Random Forest in predicting the attrition of your valuable employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from IPython.display import Image\n",
    "from six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload 'hr' dataset\n",
    "df = pd.read_csv(\"hr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "3                 3          4  Life Sciences              1               5   \n",
       "4                 2          1        Medical              1               7   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "3  ...                         3            80                 0   \n",
       "4  ...                         4            80                 1   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "3                  8                      3               3               8   \n",
       "4                  6                      3               3               2   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "3                  7                        3                     0  \n",
       "4                  2                        2                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the first 5 rows of your dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Attrition', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a countplot of the \"Attrition\" column in this dataframe to view if classes are balanced\n",
    "sns.countplot(x='Attrition', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"EmployeeCount\", 'EmployeeNumber', 'Over18', 'StandardHours' hours along the column axis \n",
    "df.drop([\"EmployeeCount\", \"EmployeeNumber\", \"Over18\", \"StandardHours\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of categorical columns where unique samples are less than 50\n",
    " \n",
    "categorical_col = []\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == object and len(df[column].unique()) <= 50:\n",
    "        categorical_col.append(column)\n",
    "        \n",
    "df['Attrition'] = df.Attrition.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 'Attrition' column from the 'categorical_col' \n",
    "categorical_col.remove('Attrition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform select categorical columns into dummies\n",
    "label = LabelEncoder()\n",
    "for column in categorical_col:\n",
    "    df[column] = label.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'X' and 'Y' training set, where 'X' is simply the dataframe without the 'Attrition' column\n",
    "X = df.drop('Attrition', axis=1)\n",
    "\n",
    "# and 'Y' is the 'Attrition' column\n",
    "y = df['Attrition']\n",
    "\n",
    "# create 'train_test_split' splits on the X and Y data where the test_size is 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a `print_score` method to generate a report\n",
    " \n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Decision Tree parameters:\n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.  \n",
    "\n",
    "splitter: The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split.  \n",
    "\n",
    "max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.  \n",
    "\n",
    "min_samples_split: The minimum number of samples required to split an internal node.  \n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.  \n",
    "\n",
    "min_weight_fraction_leaf: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.  \n",
    "\n",
    "max_features: The number of features to consider when looking for the best split.  \n",
    "\n",
    "max_leaf_nodes: Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.  \n",
    "\n",
    "min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "min_impurity_split: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a simple DecisionTreeClassifier object\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# fit on X_train & y_train data\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    853.0  176.0       1.0     1029.0        1029.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[853   0]\n",
      " [  0 176]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 77.78%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.887363   0.259740  0.777778    0.573551      0.800549\n",
      "recall       0.850000   0.327869  0.777778    0.588934      0.777778\n",
      "f1-score     0.868280   0.289855  0.777778    0.579067      0.788271\n",
      "support    380.000000  61.000000  0.777778  441.000000    441.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[323  57]\n",
      " [ 41  20]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the report of the DecisionTree performance\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4332 candidates, totalling 21660 fits\n",
      "Best paramters: {'criterion': 'entropy', 'max_depth': 6, 'min_samples_leaf': 19, 'min_samples_split': 2, 'splitter': 'best'})\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 86.78%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.887568    0.692308  0.867833     0.789938      0.854170\n",
      "recall       0.962485    0.409091  0.867833     0.685788      0.867833\n",
      "f1-score     0.923510    0.514286  0.867833     0.718898      0.853516\n",
      "support    853.000000  176.000000  0.867833  1029.000000   1029.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[821  32]\n",
      " [104  72]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 87.30%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.891304   0.592593  0.873016    0.741948      0.849986\n",
      "recall       0.971053   0.262295  0.873016    0.616674      0.873016\n",
      "f1-score     0.929471   0.363636  0.873016    0.646554      0.851204\n",
      "support    380.000000  61.000000  0.873016  441.000000    441.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[369  11]\n",
      " [ 45  16]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for the best possible hyperparameters, using GridSearchCV\n",
    "# NOTE: This might take some time\n",
    "\n",
    "params = {\n",
    "    \"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    \"max_depth\":(list(range(1, 20))), \n",
    "    \"min_samples_split\":[2, 3, 4], \n",
    "    \"min_samples_leaf\":list(range(1, 20)), \n",
    "}\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "# TODO: Implement `GridSearchCV` object\n",
    "tree_cv = GridSearchCV(\n",
    "    tree_clf, \n",
    "    params, \n",
    "    scoring=\"f1\", \n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f\"Best paramters: {best_params})\")\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Random forest algorithm parameters:\n",
    "\n",
    "n_estimators: The number of trees in the forest.  \n",
    "\n",
    "criterion: The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.  \n",
    " \n",
    "min_samples_split: The minimum number of samples required to split an internal node.  \n",
    "\n",
    "min_samples_leaf: The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.  \n",
    "\n",
    "min_weight_fraction_leaf: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.  \n",
    "\n",
    "max_features: The number of features to consider when looking for the best split.  \n",
    "\n",
    "max_leaf_nodes: Grow a tree with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes.  \n",
    "\n",
    "min_impurity_decrease: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.  \n",
    "\n",
    "min_impurity_split: Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.  \n",
    "\n",
    "bootstrap: Whether bootstrap samples are used when building trees. If False, the whole datset is used to build each tree.  \n",
    "\n",
    "oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 'RandomForestClassifier' \n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fit the randomforest object using the X_train & y_train data\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               0      1  accuracy  macro avg  weighted avg\n",
      "precision    1.0    1.0       1.0        1.0           1.0\n",
      "recall       1.0    1.0       1.0        1.0           1.0\n",
      "f1-score     1.0    1.0       1.0        1.0           1.0\n",
      "support    853.0  176.0       1.0     1029.0        1029.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[853   0]\n",
      " [  0 176]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 86.39%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0          1  accuracy   macro avg  weighted avg\n",
      "precision    0.872093   0.545455  0.863946    0.708774      0.826912\n",
      "recall       0.986842   0.098361  0.863946    0.542601      0.863946\n",
      "f1-score     0.925926   0.166667  0.863946    0.546296      0.820904\n",
      "support    380.000000  61.000000  0.863946  441.000000    441.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[375   5]\n",
      " [ 55   6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a report on the random forest model\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "# search for the best possible hyperparameters, using RandomSearchCV\n",
    "# NOTE: This might take some time\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth, \n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf, \n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "# TODO: Implement `RandomizedSearchCV` object\n",
    "rf_cv = RandomizedSearchCV(\n",
    "    estimator=rf_clf, \n",
    "    scoring='f1',\n",
    "    param_distributions=random_grid, \n",
    "    n_iter=200, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best paramters: {rf_best_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(**rf_best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "\n",
    "In this notebook we learned the following lessons:\n",
    "\n",
    "* Decision tree and random forest algorithms and the parameters of each algorithm.  \n",
    "* How to tune hyperparameters for both Decision tree and Random Forest.  \n",
    "* Balance your dataset before training to prevent the tree from being biased toward the classes that are dominant.\n",
    "    * By sampling an equal number of samples from each class\n",
    "    * By normalizing the sum of the sample weights (sample_weight) for each class to the same value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
